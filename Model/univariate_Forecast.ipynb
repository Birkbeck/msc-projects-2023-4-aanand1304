{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import matplotlib.dates as mdates  # For better date formatting on the x-axis\n",
    "\n",
    "# SMAPE calculation function\n",
    "def smape(yTrue, yPred):\n",
    "    \"\"\"SMAPE is used to evaluate the accuracy of the predictions.\"\"\"\n",
    "    denominator = (np.abs(yTrue) + np.abs(yPred))\n",
    "    smape_value = np.mean(2 * np.abs(yPred - yTrue) / np.where(denominator == 0, 1, denominator)) * 100\n",
    "    return smape_value\n",
    "\n",
    "# Exponential Smoothing for Time Series\n",
    "def exponential_smoothing(series, alpha):\n",
    "    \"\"\"Apply exponential smoothing to a time series. reduces noise by smoothing out fluctuations.\"\"\"\n",
    "\n",
    "    result = [series[0]] \n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return np.array(result)\n",
    "\n",
    "# Double Exponential Smoothing for Time Series\n",
    "def double_exponential_smoothing(series, alpha, beta):\n",
    "    \"\"\"\n",
    "    Apply double exponential smoothing to a time series, smoothing the level, and Beta is for smoothing the trend.\n",
    "    \"\"\"\n",
    "    result = [series[0]]\n",
    "    level, trend = series[0], series[1] - series[0]  \n",
    "    for n in range(1, len(series)):\n",
    "        value = series[n]\n",
    "        last_level, level = level, alpha * value + (1 - alpha) * (level + trend)\n",
    "        trend = beta * (level - last_level) + (1 - beta) * trend\n",
    "        result.append(level + trend)\n",
    "    return np.array(result)\n",
    "\n",
    "# Prepare the data for LSTM input\n",
    "def prepare_data(data, n_input):\n",
    "\n",
    "    \"\"\"Transform the time series data into sequences of input-output pairs for LSTM training \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_input):\n",
    "        X.append(data[i:(i + n_input)])  # Input sequence of n_input time steps\n",
    "        y.append(data[i + n_input])      # Output: the value immediately following the input sequence\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Build LSTM Model with Monte Carlo Dropout for Uncertainty Estimation\n",
    "def build_mc_dropout_model(n_input, units, dropout_rate):\n",
    "\n",
    "    \"\"\"Build an LSTM model with Monte Carlo Dropout for uncertainty estimation\"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(n_input, 1)))  # Input: sequence of n_input time steps with one feature\n",
    "    \n",
    "    # Add LSTM layers with Dropout\n",
    "    model.add(LSTM(units[0], activation='relu', return_sequences=(len(units) > 1)))  # First LSTM layer\n",
    "    model.add(Dropout(dropout_rate))  # Apply dropout\n",
    "    \n",
    "    # Additional LSTM layers (if any)\n",
    "    for unit in units[1:]:\n",
    "        model.add(LSTM(unit, activation='relu', return_sequences=False))  # LSTM layers\n",
    "        model.add(Dropout(dropout_rate))  # Apply dropout\n",
    "    \n",
    "    model.add(Dense(1))  # Output layer for regression\n",
    "    model.compile(optimizer='adam', loss='mse')  # Compile the model with mean squared error loss\n",
    "    return model\n",
    "\n",
    "# Monte Carlo Dropout prediction function\n",
    "def mc_dropout_predict(model, X, n_iter=100):\n",
    "    \"\"\"\n",
    "    Make predictions using Monte Carlo Dropout to estimate uncertainty.\n",
    "    n_iter determines the number of stochastic forward passes to be made.\n",
    "    \"\"\"\n",
    "    predictions = np.array([model(X, training=True) for _ in range(n_iter)])  # Dropout active during inference\n",
    "    return predictions.mean(axis=0), predictions.std(axis=0)  # Return the mean and standard deviation\n",
    "\n",
    "# Generate future dates for forecasting\n",
    "def generate_future_dates(start_date, periods):\n",
    "    \"\"\"\n",
    "    Generate a list of future dates starting from 'start_date', assuming monthly data. \"\"\"\n",
    "    return [start_date + timedelta(days=i*30) for i in range(periods)]  # Assuming 30 days per month\n",
    "\n",
    "# Step-by-step forecasting using Monte Carlo Dropout\n",
    "def step_by_step_mc_dropout_forecasting(attack_data, model, scaler, n_input, forecast_horizon, n_iterations=100):\n",
    "\n",
    "    \"\"\"Perform step-by-step forecasting using Monte Carlo Dropout.\n",
    "    Generate predictions for each time step by feeding the previous forecast as input for the next.\"\"\"\n",
    "\n",
    "    last_sequence = attack_data[-n_input:].reshape(1, n_input, 1)  # Last n_input values for forecasting\n",
    "    forecasts = []\n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "\n",
    "    for _ in range(forecast_horizon):\n",
    "        # Predict the next time step using Monte Carlo Dropout\n",
    "        next_prediction_mean, next_prediction_std = mc_dropout_predict(model, last_sequence, n_iter=n_iterations)\n",
    "        forecast = next_prediction_mean[0, 0]\n",
    "        forecasts.append(forecast)\n",
    "\n",
    "        # Calculate 95% confidence intervals\n",
    "        lower_bound = forecast - 1.96 * next_prediction_std[0, 0]\n",
    "        upper_bound = forecast + 1.96 * next_prediction_std[0, 0]\n",
    "        lower_bounds.append(lower_bound)\n",
    "        upper_bounds.append(upper_bound)\n",
    "\n",
    "        # Shift the input sequence and append the new forecast\n",
    "        last_sequence = np.roll(last_sequence, -1, axis=1)\n",
    "        last_sequence[0, -1, 0] = forecast\n",
    "\n",
    "    # Inverse transform the forecasted values back to the original scale\n",
    "    forecasts_inv = scaler.inverse_transform(np.array(forecasts).reshape(-1, 1)).flatten()\n",
    "    lower_bounds_inv = scaler.inverse_transform(np.array(lower_bounds).reshape(-1, 1)).flatten()\n",
    "    upper_bounds_inv = scaler.inverse_transform(np.array(upper_bounds).reshape(-1, 1)).flatten()\n",
    "\n",
    "    return forecasts_inv, lower_bounds_inv, upper_bounds_inv\n",
    "\n",
    "# Plot forecast and actual data with overlap\n",
    "def forecast_univariate_mc_dropout(target_variable, attack_data, scaler, model, forecast_horizon, data, last_date, output_plot_dir):\n",
    "\n",
    "    \"\"\"Generate and plot the forecast for the target variable using Monte Carlo Dropout.\"\"\"\n",
    "\n",
    "    forecasts_inv, lower_bounds_inv, upper_bounds_inv = step_by_step_mc_dropout_forecasting(\n",
    "        attack_data, model, scaler, best_params['n_input'], forecast_horizon\n",
    "    )\n",
    "\n",
    "    # Generate future dates for the forecast\n",
    "    future_dates = generate_future_dates(last_date, forecast_horizon)\n",
    "\n",
    "    # Seamless overlap: Append the last historical data point to the beginning of the forecast for smooth plot\n",
    "    seamless_forecast = np.insert(forecasts_inv, 0, data[target_variable].iloc[-1])\n",
    "    lower_bounds_inv = np.insert(lower_bounds_inv, 0, data[target_variable].iloc[-1])\n",
    "    upper_bounds_inv = np.insert(upper_bounds_inv, 0, data[target_variable].iloc[-1])\n",
    "\n",
    "    # Plot historical data and forecast with overlap and confidence intervals\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(data.index, data[target_variable], label='Actual Data', color='blue', linestyle='-')\n",
    "    plt.plot([last_date] + future_dates, seamless_forecast, label='Forecast', color='red', linestyle='-')\n",
    "    plt.fill_between([last_date] + future_dates, lower_bounds_inv, upper_bounds_inv, color='green', alpha=0.3, label='95% Confidence Interval')\n",
    "\n",
    "    plt.title(f'{target_variable} - Univariate')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Incident Count')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot for the original forecast\n",
    "    plot_name = f'{target_variable}_forecast_mc_dropout.png'\n",
    "    plot_path = os.path.join(output_plot_dir, plot_name)\n",
    "    plt.savefig(plot_path)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Forecast plot for {target_variable} saved to {plot_path}.\")\n",
    "\n",
    "# Function to run seed-based forecasting and show results\n",
    "def run_seed_forecasting(target_variable, selected_data, scaler, model, forecast_horizon, data, last_date, seed=None):\n",
    "\n",
    "    \"\"\" Perform seed-based forecasting by setting a random seed. \"\"\"\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)  # Set the seed for NumPy\n",
    "        tf.random.set_seed(seed)  # Set the seed for TensorFlow\n",
    "        print(f\"Running forecast with seed {seed}\")\n",
    "\n",
    "    # Prepare for forecast generation\n",
    "    last_sequence = selected_data[-model.input_shape[1]:]\n",
    "    forecasts, lower_bounds, upper_bounds = [], [], []\n",
    "    \n",
    "    for _ in range(forecast_horizon):\n",
    "        next_prediction_mean, next_prediction_std = mc_dropout_predict(model, last_sequence.reshape(1, model.input_shape[1], model.input_shape[2]))\n",
    "        forecasts.append(next_prediction_mean[0, 0])\n",
    "        \n",
    "        lower_bound_scaled = next_prediction_mean[0, 0] - 1.96 * next_prediction_std[0, 0]\n",
    "        upper_bound_scaled = next_prediction_mean[0, 0] + 1.96 * next_prediction_std[0, 0]\n",
    "        \n",
    "        lower_bounds.append(lower_bound_scaled)\n",
    "        upper_bounds.append(upper_bound_scaled)\n",
    "        \n",
    "        last_sequence = np.roll(last_sequence, -1, axis=0)\n",
    "        last_sequence[-1, -1] = next_prediction_mean[0, 0]\n",
    "    \n",
    "    # Inverse transform the forecasts and confidence intervals\n",
    "    dummy_array = np.zeros((len(forecasts), model.input_shape[2]))\n",
    "    dummy_array[:, -1] = forecasts\n",
    "    forecasts_inv = scaler.inverse_transform(dummy_array)[:, -1]\n",
    "    \n",
    "    dummy_array[:, -1] = lower_bounds\n",
    "    lower_bounds_inv = scaler.inverse_transform(dummy_array)[:, -1]\n",
    "    \n",
    "    dummy_array[:, -1] = upper_bounds\n",
    "    upper_bounds_inv = scaler.inverse_transform(dummy_array)[:, -1]\n",
    "    \n",
    "    # Generate future dates for the forecast\n",
    "    future_dates = generate_future_dates(last_date, forecast_horizon)\n",
    "    future_dates = [last_date] + future_dates\n",
    "    \n",
    "    # Append the last historical data point to the beginning of the forecast for a seamless plot\n",
    "    seamless_forecast = np.insert(forecasts_inv, 0, data[target_variable].iloc[-1])\n",
    "    lower_bounds_inv = np.insert(lower_bounds_inv, 0, data[target_variable].iloc[-1])\n",
    "    upper_bounds_inv = np.insert(upper_bounds_inv, 0, data[target_variable].iloc[-1])\n",
    "    \n",
    "    # Plot the historical data and forecast\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(data.index, data[target_variable], label='Actual Data', color='blue', linestyle='-')\n",
    "    plt.plot(future_dates, seamless_forecast, label=f'Forecast (Seed {seed})', color='red', linestyle='--')\n",
    "    plt.fill_between(future_dates, lower_bounds_inv, upper_bounds_inv, color='green', alpha=0.3, label='95% Confidence Interval')\n",
    "\n",
    "    plt.title(f'{target_variable} - Forecast with Seed {seed}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Incident Count')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    plt.gcf().autofmt_xdate()  # Rotate dates for better readability\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main execution for univariate forecasting with Monte Carlo Dropout\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    data = pd.read_csv('FinalDataset.csv')\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%b-%y')\n",
    "    data.set_index('Date', inplace=True)\n",
    "\n",
    "    attacks = ['DDoS-ALL', 'Phishing-ALL', 'Ransomware-ALL', 'Password Attack-ALL', 'SQL Injection-ALL', 'Account Hijacking-ALL', \n",
    "            'Defacement-ALL', 'Trojan-ALL', 'Vulnerability-ALL', 'Zero-day-ALL', 'Malware-ALL', 'Advanced persistent threat-ALL', \n",
    "            'XSS-ALL', 'Data Breach-ALL', 'Disinformation/Misinformation-ALL', 'Targeted Attack-ALL','Adware-ALL',\n",
    "            'Brute Force Attack-ALL', 'Malvertising-ALL', 'Backdoor-ALL', 'Botnet-ALL', 'Cryptojacking-ALL',\n",
    "            'Worms-ALL', 'Spyware-ALL']\n",
    "\n",
    "    param_dir = 'univariateparam25'\n",
    "    output_plot_dir = 'univariate_forecast_plots_36months_U'\n",
    "    os.makedirs(output_plot_dir, exist_ok=True)\n",
    "\n",
    "    n_forecast = 36  # Forecast horizon (36 months)\n",
    "\n",
    "    for attack in attacks:\n",
    "        print(f\"Forecasting for attack: {attack}\")\n",
    "\n",
    "        # Load best parameters for the current attack\n",
    "        with open(os.path.join(param_dir, f'{attack}_best_params.json'), 'r') as f:\n",
    "            best_params = json.load(f)['Best Parameters']\n",
    "\n",
    "        # Preprocess the attack data\n",
    "        attack_data = data[attack].values.reshape(-1, 1)\n",
    "        scaler = RobustScaler()\n",
    "        attack_data_scaled = scaler.fit_transform(attack_data)\n",
    "\n",
    "        # Build the model using the best hyperparameters with Monte Carlo Dropout\n",
    "        model = build_mc_dropout_model(best_params['n_input'], best_params['units'], best_params['dropout_rate'])\n",
    "\n",
    "        # Prepare data for model training\n",
    "        X_train, y_train = prepare_data(attack_data_scaled, best_params['n_input'])\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=best_params['n_epochs'], batch_size=40, verbose=0)\n",
    "\n",
    "        # Forecast future values using the original model\n",
    "        forecast_univariate_mc_dropout(attack, attack_data_scaled, scaler, model, n_forecast, data, data.index[-1], output_plot_dir)\n",
    "\n",
    "        # Perform seed-based forecasting (showing results only)\n",
    "        for seed in [1, 2, 3]:\n",
    "            run_seed_forecasting(attack, attack_data_scaled, scaler, model, n_forecast, data, data.index[-1], seed=seed)\n",
    "\n",
    "print(\"Univariate forecasting seed-based forecasting completed for all attacks.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
